{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np                                       # fast vectors and matrices\n",
    "import matplotlib.pyplot as plt                          # plotting\n",
    "from scipy.fftpack import fft\n",
    "\n",
    "from intervaltree import Interval,IntervalTree\n",
    "\n",
    "from time import time\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = 16                  # pool size\n",
    "stride = 8              # stride between pooled features\n",
    "window = 16384          # size of the convolutional window\n",
    "d = 2048                # receptive field\n",
    "npools = (((window - d)/stride+1)/(p/2)-1)\n",
    "k = 500                 # hidden nodes\n",
    "m = 128                 # number of notes\n",
    "fs = 44100              # samples/second\n",
    "features = 0\n",
    "labels = 1\n",
    "\n",
    "restore_weights = True\n",
    "folder = 'convnet/'\n",
    "\n",
    "musicnet = os.environ['MUSICNET']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MusicNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = dict(np.load(open(musicnet,'rb')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split our the test set\n",
    "test_data = dict()\n",
    "for id in (2303,2382,1819): # test set\n",
    "    test_data[str(id)] = train_data.pop(str(id))\n",
    "    \n",
    "train_ids = train_data.keys()\n",
    "test_ids = test_data.keys()\n",
    "    \n",
    "print len(train_data)\n",
    "print len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create the test set\n",
    "samples = 7500\n",
    "Xtest = np.zeros([3*samples,1,window,1])\n",
    "Ytest = np.zeros([3*samples,m])\n",
    "for i in range(len(test_ids)):\n",
    "    for j in range(samples):\n",
    "        index = int(fs)+j*512 # start from one second to give us some wiggle room for larger segments\n",
    "        Xtest[samples*i + j] = test_data[test_ids[i]][features][index:index+window].reshape(1,window,1)\n",
    "        Xtest[7500*i + j] /= np.linalg.norm(Xtest[7500*i + j]) + 10e-6\n",
    "        \n",
    "        # label stuff that's on in the center of the window\n",
    "        for label in test_data[test_ids[i]][labels][index+window/2]:\n",
    "            Ytest[samples*i + j,label.data[1]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(999)\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None,1,window,1])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, m])\n",
    "\n",
    "scale = 10e-7\n",
    "w = tf.Variable(scale*tf.random_normal([1,d,1,k],seed=999))\n",
    "beta = tf.Variable(scale*tf.random_normal([npools*k,m],seed=999))\n",
    "\n",
    "zx = tf.log(tf.constant(1.) + tf.nn.relu(tf.nn.conv2d(x,w,strides=[1,1,stride,1],padding='VALID')))\n",
    "zxpool = tf.nn.avg_pool(zx,ksize=[1,1,p,1],strides=[1,1,p/2,1],padding='VALID')\n",
    "\n",
    "y = tf.matmul(tf.squeeze(tf.reshape(zxpool,[tf.shape(x)[0],1,npools*k])),beta)\n",
    "L = tf.reduce_mean(tf.nn.l2_loss(y-y_))\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if restore_weights:\n",
    "    weights = np.load(open(folder + 'w.npy','rb'))\n",
    "    coefficients = np.load(open(folder + 'beta.npy','rb'))\n",
    "    average_precision = list(np.load(open(folder + 'ap.npy','rb')))\n",
    "    square_error = list(np.load(open(folder + 'loss.npy','rb')))\n",
    "    weights_top = list(np.load(open(folder + 'wtop.npy','rb')))\n",
    "    weights_bottom = list(np.load(open(folder + 'wbot.npy','rb')))\n",
    "\n",
    "    sess = tf.Session()\n",
    "    sess.run(w.assign(weights))\n",
    "    sess.run(beta.assign(coefficients))\n",
    "    init_lr = .01/128\n",
    "else:\n",
    "    square_error = []\n",
    "    weights_top = []\n",
    "    weights_bottom = []\n",
    "    average_precision = []\n",
    "    sess = tf.Session()\n",
    "    sess.run(init)\n",
    "    init_lr = .01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr = init_lr\n",
    "train_step = tf.train.GradientDescentOptimizer(lr).minimize(L)\n",
    "Xmb = np.empty([len(train_data),1,window,1])\n",
    "start = time()\n",
    "print 'iter\\tsquare_loss\\tweights_top\\tweights_bottom\\tavg_prec\\ttime\\t\\teval_time'\n",
    "for i in xrange(100000):\n",
    "    if i % 100 == 0 and (i != 0 or len(square_error) == 0):\n",
    "        eval_time = time()\n",
    "        \n",
    "        # split up test set\n",
    "        se = 0.\n",
    "        subdiv = 50\n",
    "        subset = Xtest.shape[0]/subdiv\n",
    "        for j in range(subdiv):\n",
    "            se += sess.run(L, feed_dict={x: Xtest[subset*j:subset*(j+1)], y_: Ytest[subset*j:subset*(j+1)]})/subset\n",
    "        square_error.append(se/50)\n",
    "        #square_error.append(sess.run(L, feed_dict={x: Xtest[0:3000], y_: Ytest[0:3000]})/Xtest.shape[0])\n",
    "        weights_top.append(np.mean(np.linalg.norm(beta.eval(session=sess),axis=0)))\n",
    "        weights_bottom.append(np.mean(np.linalg.norm(w.eval(session=sess),axis=1)))\n",
    "        \n",
    "        Yhattestbase = np.empty((Xtest.shape[0],m))\n",
    "        for j in range(subdiv):\n",
    "            Yhattestbase[subset*j:subset*(j+1)] = sess.run(y,feed_dict={x: Xtest[subset*j:subset*(j+1)]})\n",
    "        #Yhattestbase = sess.run(y,feed_dict={x: Xtest})\n",
    "        yflat = Ytest.reshape(Ytest.shape[0]*Ytest.shape[1])\n",
    "        yhatflat = Yhattestbase.reshape(Yhattestbase.shape[0]*Yhattestbase.shape[1])\n",
    "        average_precision.append(average_precision_score(yflat, yhatflat))\n",
    "        \n",
    "        end = time()\n",
    "        print i,'\\t', square_error[-1],\\\n",
    "                '\\t', weights_top[-1],\\\n",
    "                '\\t', weights_bottom[-1],\\\n",
    "                '\\t', average_precision[-1],\\\n",
    "                '\\t',end-start,\\\n",
    "                '\\t',end-eval_time\n",
    "        start = time()\n",
    "    \n",
    "    Ymb = np.zeros([len(train_data),m])\n",
    "    for j in range(len(train_data)):\n",
    "        s = np.random.randint(window/2,len(train_data[train_ids[j]][features])-window/2)\n",
    "        Xmb[j] = train_data[train_ids[j]][features][s-window/2:s+window/2].reshape(1,window,1)\n",
    "        Xmb[j] /= np.linalg.norm(Xmb[j]) + 10e-6\n",
    "        for label in train_data[train_ids[j]][labels][s]:\n",
    "            Ymb[j,label.data[1]] = 1\n",
    "\n",
    "    sess.run(train_step, feed_dict={x: Xmb, y_: Ymb})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "burnin=1\n",
    "fig, ((ax1, ax2),(ax3,ax4)) = plt.subplots(2, 2)\n",
    "fig.set_figwidth(12)\n",
    "fig.set_figheight(10)\n",
    "ax1.set_title('average precision')\n",
    "ax1.plot(average_precision[burnin:],color='g')\n",
    "ax2.set_title('square loss')\n",
    "ax2.plot(square_error[burnin:],color='g')\n",
    "ax3.set_title('weights top')\n",
    "ax3.plot(weights_top[burnin:],color='g')\n",
    "ax4.set_title('weights bottom')\n",
    "ax4.plot(weights_bottom[burnin:],color='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "offset = 20\n",
    "f, ax = plt.subplots(20,3, sharey=False)\n",
    "f.set_figheight(20)\n",
    "f.set_figwidth(20)\n",
    "weights = w.eval(session=sess)[0,:,0,:]\n",
    "for i in range(20):\n",
    "    ax[i,0].plot(weights[10:-10,i+offset], color=(41/255.,104/255.,168/255.))\n",
    "    ax[i,0].set_xlim([-20,d+20])\n",
    "    ax[i,0].set_ylim([np.min(weights[10:-10,i+offset]),np.max(weights[10:-10,i+offset])])\n",
    "    ax[i,0].set_xticklabels([])\n",
    "    ax[i,0].set_yticklabels([])\n",
    "    ax[i,1].plot(weights[d/2-1024:d/2+1024,i+offset], color=(41/255.,104/255.,168/255.))\n",
    "    ax[i,1].set_xticklabels([])\n",
    "    ax[i,1].set_yticklabels([])\n",
    "    ax[i,1].set_xlim([0,2048])\n",
    "    ax[i,2].plot(np.abs(fft(weights[d/2-1024:d/2+1024,i+offset]))[0:200], color=(41/255.,104/255.,168/255.))\n",
    "    ax[i,2].set_xticklabels([])\n",
    "    ax[i,2].set_yticklabels([])\n",
    "    \n",
    "for i in range(ax.shape[0]):\n",
    "    for j in range(ax.shape[1]):\n",
    "        ax[i,j].set_xticks([])\n",
    "        ax[i,j].set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folder = 'convnet_small/'\n",
    "\n",
    "weights = w.eval(session=sess)\n",
    "coefficients = beta.eval(session=sess)\n",
    "\n",
    "np.save(open(folder + 'w.npy','wb'),weights)\n",
    "np.save(open(folder + 'beta.npy','wb'),coefficients)\n",
    "np.save(open(folder + 'ap.npy','wb'),average_precision)\n",
    "np.save(open(folder + 'loss.npy','wb'),square_error)\n",
    "np.save(open(folder + 'wtop.npy','wb'),weights_top)\n",
    "np.save(open(folder + 'wbot.npy','wb'),weights_bottom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = 1000              # training data points per recording\n",
    "\n",
    "# sufficient statistics for least squares\n",
    "XTX = np.zeros((npools*k,npools*k))\n",
    "XTY = np.zeros((npools*k,m))\n",
    "\n",
    "# Warning: this could take some time\n",
    "Xs = np.empty((n,npools*k))\n",
    "for recording in train_data:\n",
    "    print recording, ',',\n",
    "    X,Y = train_data[recording]\n",
    "    s = np.random.randint(window/2,len(X)-window/2,n)\n",
    "    Ys = np.zeros((n,m))\n",
    "    for i in range(n):\n",
    "        Xnorm = X[s[i]-window/2:s[i]+window/2]\n",
    "        Xnorm /= np.linalg.norm(Xnorm) + 10e-6\n",
    "        \n",
    "        Xs[i] = sess.run(zxpool,feed_dict={x: Xnorm.reshape(1,1,window,1)}).reshape(npools*k)\n",
    "        for label in Y[s[i]]:\n",
    "            Ys[i,label.data[1]] = 1\n",
    "    XTX += (1./n)*np.dot(Xs.T,Xs)\n",
    "    XTY += (1./n)*np.dot(Xs.T,Ys)\n",
    "XTX /= float(len(train_data))\n",
    "XTY /= float(len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid = [2**i for i in range(-25,-10)]\n",
    "ap_ls = []\n",
    "for r in grid:\n",
    "    print r,', ',\n",
    "    betals = np.linalg.solve(XTX + r*np.eye(XTX.shape[0]),XTY)\n",
    "    \n",
    "    Yhat = np.dot(sess.run(zx,feed_dict={x: Xtest}).reshape(len(Xtest),(2*p+1)*k),betals)\n",
    "    yflat = Ytest.reshape(Ytest.shape[0]*Ytest.shape[1])\n",
    "    yhatflat = Yhat.reshape(Yhat.shape[0]*Yhat.shape[1])\n",
    "    ap_ls.append(average_precision_score(yflat, yhatflat))\n",
    "    \n",
    "fig = plt.figure()\n",
    "plt.plot(range(-25,-10),ap_ls,color=(41/255.,104/255.,168/255.),linewidth=3)\n",
    "fig.axes[0].set_xlabel('regularizer (order of magnitude)')\n",
    "fig.axes[0].set_ylabel('average precision')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIREX evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def estimate(X,subdiv=50):\n",
    "    subset = X.shape[0]/subdiv\n",
    "    Yhatbase = np.empty((X.shape[0],m))\n",
    "    for j in range(subdiv):\n",
    "        Yhatbase[subset*j:subset*(j+1)] = sess.run(y,feed_dict={x: X[subset*j:subset*(j+1)]})\n",
    "        \n",
    "    return Yhatbase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mir_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xvalidation = np.zeros([50*len(train_data),window])\n",
    "Yvalidation = np.zeros([50*len(train_data),m])\n",
    "for i in range(len(train_data)):\n",
    "    # 50 random samples from each recording\n",
    "    s = np.random.randint(window/2,len(train_data[train_ids[i]][features])-window/2,size=100)\n",
    "    for j in range(50):\n",
    "        Xvalidation[50*i+j] = train_data[train_ids[i]][features][s[j]-window/2:s[j]+window/2]\n",
    "        Xvalidation[50*i+j] /= np.linalg.norm(Xvalidation[50*i+j]) + 10e-6\n",
    "        # label stuff that's on in the center of the window\n",
    "        for label in train_data[train_ids[i]][labels][s[j]]:\n",
    "            Yvalidation[50*i+j,label.data[1]] = 1\n",
    "            \n",
    "Xvalidation = Xvalidation.reshape(Xvalidation.shape[0],1,Xvalidation.shape[1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Yhatbase = np.dot(sess.run(zx,feed_dict={x: Xvalidation}).reshape(len(Xvalidation),(2*p+1)*k),betals)\n",
    "subdiv = 50\n",
    "subset = Xvalidation.shape[0]/subdiv\n",
    "Yhatbase = np.empty((Xvalidation.shape[0],m))\n",
    "for j in range(subdiv):\n",
    "    Yhatbase[subset*j:subset*(j+1)] = sess.run(y,feed_dict={x: Xvalidation[subset*j:subset*(j+1)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# single threshold\n",
    "density = 500\n",
    "P = np.empty(density)\n",
    "R = np.empty(density)\n",
    "F = np.empty(density)\n",
    "for i in np.arange(density):\n",
    "    if i % 100 == 0: print '.',\n",
    "    c = i/float(density)\n",
    "    Yhat = Yhatbase>c\n",
    "    true_positives = np.sum(Yhat*Yvalidation)\n",
    "    P[i] = true_positives/np.sum(Yhat)\n",
    "    R[i] = true_positives/np.sum(Yvalidation)\n",
    "    F[i] = 2*(P[i]*R[i])/(P[i]+R[i])\n",
    "\n",
    "plt.plot(F)\n",
    "i = np.argmax(F)\n",
    "c = i/float(density)\n",
    "print c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(R,P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subset = Xtest.shape[0]/subdiv\n",
    "Yhattestbase = np.empty((Xtest.shape[0],m))\n",
    "for j in range(subdiv):\n",
    "    Yhattestbase[subset*j:subset*(j+1)] = sess.run(y,feed_dict={x: Xtest[subset*j:subset*(j+1)]})\n",
    "Yhat = Yhattestbase>c\n",
    "true_positives = np.sum(Yhat*Ytest)\n",
    "P = true_positives/(np.sum(Yhat))\n",
    "R = true_positives/(np.sum(Ytest))\n",
    "F = 2*(P*R)/(P+R)\n",
    "print P\n",
    "print R\n",
    "print F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yflat = Ytest.reshape(Ytest.shape[0]*Ytest.shape[1])\n",
    "yhatflat = Yhattestbase.reshape(Yhattestbase.shape[0]*Yhattestbase.shape[1])\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(yflat, yhatflat)\n",
    "ap = average_precision_score(yflat, yhatflat)\n",
    "plt.plot(recall,precision)\n",
    "print ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Yhatbase = np.dot(sess.run(zx,feed_dict={x: Xtest}).reshape(len(Xtest),(2*p+1)*k),betals)\n",
    "subdiv = 50\n",
    "subset = Xtest.shape[0]/subdiv\n",
    "Yhatbase = np.empty((Xtest.shape[0],m))\n",
    "for j in range(subdiv):\n",
    "    Yhatbase[subset*j:subset*(j+1)] = sess.run(y,feed_dict={x: Xtest[subset*j:subset*(j+1)]})\n",
    "\n",
    "Yhat = Yhatbase>c\n",
    "Yhatlist = []\n",
    "Ytestlist = []\n",
    "for i in range(len(Yhat)):\n",
    "    fhat = []\n",
    "    ftest = []\n",
    "    for note in range(128):\n",
    "        if Yhat[i][note] == 1:\n",
    "            fhat.append(440.*2**((note - 69.)/12.))\n",
    "        if Ytest[i][note] == 1:\n",
    "            ftest.append(440.*2**((note - 69.)/12.))\n",
    "    Yhatlist.append(np.array(fhat))\n",
    "    Ytestlist.append(np.array(ftest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "P,R,Acc,Esub,Emiss,Efa,Etot,cP,cR,cAcc,cEsub,cEmiss,cEfa,cEtot = \\\n",
    "mir_eval.multipitch.metrics(np.arange(len(Ytestlist))/100.,Ytestlist,np.arange(len(Yhatlist))/100.,Yhatlist)\n",
    "\n",
    "print P\n",
    "print R\n",
    "print Acc\n",
    "print Etot\n",
    "print Esub\n",
    "print Emiss\n",
    "print Efa\n",
    "\n",
    "print '-----'\n",
    "\n",
    "print cP\n",
    "print cR\n",
    "print cAcc\n",
    "print cEtot\n",
    "print cEsub\n",
    "print cEmiss\n",
    "print cEfa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Precision/Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fs = 44100.\n",
    "m = 128\n",
    "\n",
    "composition = 2\n",
    "\n",
    "# create the test set (INDIVIDUAL COMPOSITIONS)\n",
    "samples = 7500\n",
    "Xtest = np.zeros([samples,1,window,1])\n",
    "Ytest = np.zeros([samples,m])\n",
    "for i in range(1):\n",
    "    for j in range(samples):\n",
    "        index = int(fs)+j*512 # start from one second to give us some wiggle room for larger segments\n",
    "        Xtest[samples*i + j] = test_data[test_ids[composition]][features][index:index+window].reshape(1,window,1)\n",
    "        Xtest[7500*i + j] /= np.linalg.norm(Xtest[7500*i + j]) + 10e-6\n",
    "        \n",
    "        # label stuff that's on in the center of the window\n",
    "        for label in test_data[test_ids[i+composition]][labels][index+window/2]:\n",
    "            Ytest[samples*i + j,label.data[1]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print test_ids[composition]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subset = Xvalidation.shape[0]/subdiv\n",
    "Yhatbase = np.empty((Xvalidation.shape[0],m))\n",
    "for j in range(subdiv):\n",
    "    Yhatbase[subset*j:subset*(j+1)] = sess.run(y,feed_dict={x: Xvalidation[subset*j:subset*(j+1)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# single threshold\n",
    "density = 500\n",
    "P = np.empty(density)\n",
    "R = np.empty(density)\n",
    "F = np.empty(density)\n",
    "for i in np.arange(density):\n",
    "    if i % 100 == 0: print '.',\n",
    "    c = i/float(density)\n",
    "    Yhat = Yhatbase>c\n",
    "    true_positives = np.sum(Yhat*Yvalidation)\n",
    "    P[i] = true_positives/np.sum(Yhat)\n",
    "    R[i] = true_positives/np.sum(Yvalidation)\n",
    "    F[i] = 2*(P[i]*R[i])/(P[i]+R[i])\n",
    "\n",
    "plt.plot(F)\n",
    "i = np.argmax(F)\n",
    "c = i/float(density)\n",
    "print c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(R,P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subset = Xtest.shape[0]/subdiv\n",
    "Yhattestbase = np.empty((Xtest.shape[0],m))\n",
    "for j in range(subdiv):\n",
    "    Yhattestbase[subset*j:subset*(j+1)] = sess.run(y,feed_dict={x: Xtest[subset*j:subset*(j+1)]})\n",
    "Yhat = Yhattestbase>c\n",
    "true_positives = np.sum(Yhat*Ytest)\n",
    "P = true_positives/(np.sum(Yhat))\n",
    "R = true_positives/(np.sum(Ytest))\n",
    "F = 2*(P*R)/(P+R)\n",
    "print P\n",
    "print R\n",
    "print F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yflat = Ytest.reshape(Ytest.shape[0]*Ytest.shape[1])\n",
    "yhatflat = Yhattestbase.reshape(Yhattestbase.shape[0]*Yhattestbase.shape[1])\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(yflat, yhatflat)\n",
    "ap = average_precision_score(yflat, yhatflat)\n",
    "plt.plot(recall,precision)\n",
    "print ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(recall,precision)\n",
    "fig.axes[0].set_xlabel('recall')\n",
    "fig.axes[0].set_ylabel('precision')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('convnet_pr.eps',format='eps', dpi=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breakdown of test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Yvalid1 = Yvalidation[np.sum(Yvalidation,axis=1)==1]\n",
    "Yvalid2 = Yvalidation[np.sum(Yvalidation,axis=1)==2]\n",
    "Yvalid3 = Yvalidation[np.sum(Yvalidation,axis=1)==3]\n",
    "Yvalid4 = Yvalidation[np.sum(Yvalidation,axis=1)==4]\n",
    "Yvalid5 = Yvalidation[np.sum(Yvalidation,axis=1)==5]\n",
    "Yvalid6 = Yvalidation[np.sum(Yvalidation,axis=1)==6]\n",
    "Ytest1 = Ytest[np.sum(Ytest,axis=1)==1]\n",
    "Ytest2 = Ytest[np.sum(Ytest,axis=1)==2]\n",
    "Ytest3 = Ytest[np.sum(Ytest,axis=1)==3]\n",
    "Ytest4 = Ytest[np.sum(Ytest,axis=1)==4]\n",
    "Ytest5 = Ytest[np.sum(Ytest,axis=1)==5]\n",
    "Ytest6 = Ytest[np.sum(Ytest,axis=1)==6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Yhatbase = estimate(Xvalidation[np.sum(Yvalidation,axis=1)==1])\n",
    "Yhattestbase = estimate(Xtest[np.sum(Ytest,axis=1)==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# single threshold\n",
    "density = 500\n",
    "P = np.empty(density)\n",
    "R = np.empty(density)\n",
    "F = np.empty(density)\n",
    "for i in np.arange(density):\n",
    "    if i % 100 == 0: print '.',\n",
    "    c = i/float(density)\n",
    "    Yhat = Yhatbase>c\n",
    "    true_positives = np.sum(Yhat*Yvalid1)\n",
    "    P[i] = true_positives/np.sum(Yhat)\n",
    "    R[i] = true_positives/np.sum(Yvalid1)\n",
    "    F[i] = 2*(P[i]*R[i])/(P[i]+R[i])\n",
    "\n",
    "plt.plot(F)\n",
    "i = np.argmax(F)\n",
    "c = i/float(density)\n",
    "print c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Yhat = Yhattestbase>c\n",
    "true_positives = np.sum(Yhat*Ytest1)\n",
    "P = true_positives/(np.sum(Yhat))\n",
    "R = true_positives/(np.sum(Ytest1))\n",
    "F = 2*(P*R)/(P+R)\n",
    "print P\n",
    "print R\n",
    "print F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yflat = Ytest1.reshape(Ytest1.shape[0]*Ytest1.shape[1])\n",
    "yhatflat = Yhattestbase.reshape(Yhattestbase.shape[0]*Yhattestbase.shape[1])\n",
    "\n",
    "precision1, recall1, _ = precision_recall_curve(yflat, yhatflat)\n",
    "average_precision1 = average_precision_score(yflat, yhatflat)\n",
    "plt.plot(recall1,precision1)\n",
    "print average_precision1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Yhatbase = estimate(Xvalidation[np.sum(Yvalidation,axis=1)==4])\n",
    "Yhattestbase = estimate(Xtest[np.sum(Ytest,axis=1)==4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# single threshold\n",
    "density = 500\n",
    "P = np.empty(density)\n",
    "R = np.empty(density)\n",
    "F = np.empty(density)\n",
    "for i in np.arange(density):\n",
    "    if i % 100 == 0: print '.',\n",
    "    c = i/float(density)\n",
    "    Yhat = Yhatbase>c\n",
    "    true_positives = np.sum(Yhat*Yvalid4)\n",
    "    P[i] = true_positives/np.sum(Yhat)\n",
    "    R[i] = true_positives/np.sum(Yvalid4)\n",
    "    F[i] = 2*(P[i]*R[i])/(P[i]+R[i])\n",
    "\n",
    "plt.plot(F)\n",
    "i = np.argmax(F)\n",
    "c = i/float(density)\n",
    "print c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Yhat = Yhattestbase>c\n",
    "true_positives = np.sum(Yhat*Ytest4)\n",
    "P = true_positives/(np.sum(Yhat))\n",
    "R = true_positives/(np.sum(Ytest4))\n",
    "F = 2*(P*R)/(P+R)\n",
    "print P\n",
    "print R\n",
    "print F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yflat = Ytest4.reshape(Ytest4.shape[0]*Ytest4.shape[1])\n",
    "yhatflat = Yhattestbase.reshape(Yhattestbase.shape[0]*Yhattestbase.shape[1])\n",
    "\n",
    "precision4, recall4, _ = precision_recall_curve(yflat, yhatflat)\n",
    "average_precision4 = average_precision_score(yflat, yhatflat)\n",
    "plt.plot(recall4,precision4)\n",
    "print average_precision4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Yhatbase = sess.run(y,feed_dict={x: Xvalidation[np.sum(Yvalidation,axis=1)==2]})\n",
    "Yhattestbase = sess.run(y,feed_dict={x: Xtest[np.sum(Ytest,axis=1)==2]})\n",
    "\n",
    "# single threshold\n",
    "density = 500\n",
    "P = np.empty(density)\n",
    "R = np.empty(density)\n",
    "F = np.empty(density)\n",
    "for i in np.arange(density):\n",
    "    if i % 100 == 0: print '.',\n",
    "    c = i/float(density)\n",
    "    Yhat = Yhatbase>c\n",
    "    true_positives = np.sum(Yhat*Yvalid2)\n",
    "    P[i] = true_positives/np.sum(Yhat)\n",
    "    R[i] = true_positives/np.sum(Yvalid2)\n",
    "    F[i] = 2*(P[i]*R[i])/(P[i]+R[i])\n",
    "\n",
    "Yhat = Yhattestbase>c\n",
    "true_positives = np.sum(Yhat*Ytest2)\n",
    "P = true_positives/(np.sum(Yhat))\n",
    "R = true_positives/(np.sum(Ytest2))\n",
    "F = 2*(P*R)/(P+R)\n",
    "\n",
    "yflat = Ytest2.reshape(Ytest2.shape[0]*Ytest2.shape[1])\n",
    "yhatflat = Yhattestbase.reshape(Yhattestbase.shape[0]*Yhattestbase.shape[1])\n",
    "\n",
    "precision2, recall2, _ = precision_recall_curve(yflat, yhatflat)\n",
    "average_precision2 = average_precision_score(yflat, yhatflat)\n",
    "plt.plot(recall2,precision2)\n",
    "print average_precision2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Yhatbase = estimate(Xvalidation[np.sum(Yvalidation,axis=1)==3])\n",
    "Yhattestbase = estimate(Xtest[np.sum(Ytest,axis=1)==3])\n",
    "\n",
    "# single threshold\n",
    "density = 500\n",
    "P = np.empty(density)\n",
    "R = np.empty(density)\n",
    "F = np.empty(density)\n",
    "for i in np.arange(density):\n",
    "    if i % 100 == 0: print '.',\n",
    "    c = i/float(density)\n",
    "    Yhat = Yhatbase>c\n",
    "    true_positives = np.sum(Yhat*Yvalid3)\n",
    "    P[i] = true_positives/np.sum(Yhat)\n",
    "    R[i] = true_positives/np.sum(Yvalid3)\n",
    "    F[i] = 2*(P[i]*R[i])/(P[i]+R[i])\n",
    "\n",
    "Yhat = Yhattestbase>c\n",
    "true_positives = np.sum(Yhat*Ytest3)\n",
    "P = true_positives/(np.sum(Yhat))\n",
    "R = true_positives/(np.sum(Ytest3))\n",
    "F = 2*(P*R)/(P+R)\n",
    "\n",
    "yflat = Ytest3.reshape(Ytest3.shape[0]*Ytest3.shape[1])\n",
    "yhatflat = Yhattestbase.reshape(Yhattestbase.shape[0]*Yhattestbase.shape[1])\n",
    "\n",
    "precision3, recall3, _ = precision_recall_curve(yflat, yhatflat)\n",
    "average_precision3 = average_precision_score(yflat, yhatflat)\n",
    "plt.plot(recall3,precision3)\n",
    "print average_precision3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Yhatbase = estimate(Xvalidation[np.sum(Yvalidation,axis=1)==5])\n",
    "Yhattestbase = estimate(Xtest[np.sum(Ytest,axis=1)==5])\n",
    "\n",
    "# single threshold\n",
    "density = 500\n",
    "P = np.empty(density)\n",
    "R = np.empty(density)\n",
    "F = np.empty(density)\n",
    "for i in np.arange(density):\n",
    "    if i % 100 == 0: print '.',\n",
    "    c = i/float(density)\n",
    "    Yhat = Yhatbase>c\n",
    "    true_positives = np.sum(Yhat*Yvalid5)\n",
    "    P[i] = true_positives/np.sum(Yhat)\n",
    "    R[i] = true_positives/np.sum(Yvalid5)\n",
    "    F[i] = 2*(P[i]*R[i])/(P[i]+R[i])\n",
    "\n",
    "Yhat = Yhattestbase>c\n",
    "true_positives = np.sum(Yhat*Ytest5)\n",
    "P = true_positives/(np.sum(Yhat))\n",
    "R = true_positives/(np.sum(Ytest5))\n",
    "F = 2*(P*R)/(P+R)\n",
    "\n",
    "yflat = Ytest5.reshape(Ytest5.shape[0]*Ytest5.shape[1])\n",
    "yhatflat = Yhattestbase.reshape(Yhattestbase.shape[0]*Yhattestbase.shape[1])\n",
    "\n",
    "precision5, recall5, _ = precision_recall_curve(yflat, yhatflat)\n",
    "average_precision5 = average_precision_score(yflat, yhatflat)\n",
    "plt.plot(recall5,precision5)\n",
    "print average_precision5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Yhatbase = estimate(Xvalidation[np.sum(Yvalidation,axis=1)==6])\n",
    "Yhattestbase = estimate(Xtest[np.sum(Ytest,axis=1)==6])\n",
    "\n",
    "# single threshold\n",
    "density = 500\n",
    "P = np.empty(density)\n",
    "R = np.empty(density)\n",
    "F = np.empty(density)\n",
    "for i in np.arange(density):\n",
    "    if i % 100 == 0: print '.',\n",
    "    c = i/float(density)\n",
    "    Yhat = Yhatbase>c\n",
    "    true_positives = np.sum(Yhat*Yvalid6)\n",
    "    P[i] = true_positives/np.sum(Yhat)\n",
    "    R[i] = true_positives/np.sum(Yvalid6)\n",
    "    F[i] = 2*(P[i]*R[i])/(P[i]+R[i])\n",
    "\n",
    "Yhat = Yhattestbase>c\n",
    "true_positives = np.sum(Yhat*Ytest6)\n",
    "P = true_positives/(np.sum(Yhat))\n",
    "R = true_positives/(np.sum(Ytest6))\n",
    "F = 2*(P*R)/(P+R)\n",
    "\n",
    "yflat = Ytest6.reshape(Ytest6.shape[0]*Ytest6.shape[1])\n",
    "yhatflat = Yhattestbase.reshape(Yhattestbase.shape[0]*Yhattestbase.shape[1])\n",
    "\n",
    "precision6, recall6, _ = precision_recall_curve(yflat, yhatflat)\n",
    "average_precision6 = average_precision_score(yflat, yhatflat)\n",
    "plt.plot(recall6,precision6)\n",
    "print average_precision6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 16})\n",
    "\n",
    "thickness = 3\n",
    "\n",
    "fig = plt.figure()\n",
    "total, = plt.plot(recall,precision,color=(41/255.,104/255.,168/255.),linewidth=thickness)\n",
    "one, = plt.plot(recall1,precision1,color=(70/255.,179/255.,76/255.),linewidth=thickness)\n",
    "#two, = plt.plot(recall2,precision2,color='c')\n",
    "three, = plt.plot(recall3,precision3,color=(180/255.,50/255.,47/255.),linewidth=thickness)\n",
    "#four, = plt.plot(recall4,precision4,color='m')\n",
    "#five, = plt.plot(recall5,precision5,color='y')\n",
    "#six, = plt.plot(recall6,precision6,color='k')\n",
    "ax = fig.axes[0]\n",
    "leg = ax.legend([total,one,three],['overall','one-note','three-notes'],\\\n",
    "          loc='upper right',ncol=1,prop={'size':11})\n",
    "for legobj in leg.legendHandles:\n",
    "    legobj.set_linewidth(7.0)\n",
    "ax.set_xlabel('recall')\n",
    "ax.set_ylabel('precision')\n",
    "plt.tight_layout()\n",
    "plt.savefig('prcurve.eps',format='eps', dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
